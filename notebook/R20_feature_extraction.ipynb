{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "from maleo.wizard import Wizard\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/data_7200/*.json'\n",
    "profile_data_path = '../data/profile_id.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get media and url link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_media_and_url(data):\n",
    "    media_type = None\n",
    "    url_link = None\n",
    "    \n",
    "    if 'quoted_status' not in data:\n",
    "        try:\n",
    "            media_type = data['extended_entities']['media'][0]['type']\n",
    "        except:\n",
    "            pass\n",
    "        if media_type != 'photo' and data['entities']['urls'] != []:\n",
    "            url_link = data['entities']['urls'][0]['expanded_url']\n",
    "    return media_type, url_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_youtube_title(url_link):\n",
    "    import urllib.request\n",
    "    import json\n",
    "    import urllib\n",
    "    \n",
    "    VideoID = url_link.split('/')[-1] \n",
    "\n",
    "    params = {\"format\": \"json\", \"url\": \"https://www.youtube.com/watch?v=%s\" % VideoID}\n",
    "    url = \"https://www.youtube.com/oembed\"\n",
    "    query_string = urllib.parse.urlencode(params)\n",
    "    url = url + \"?\" + query_string\n",
    "\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        response_text = response.read()\n",
    "        data = json.loads(response_text.decode())\n",
    "        return data['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_url_title(data):\n",
    "    media_type, url_link = get_media_and_url(data)\n",
    "    \n",
    "    if url_link == None:\n",
    "        title = None\n",
    "    elif url_link.split('/')[-2] == 'youtu.be':\n",
    "        title = get_youtube_title(url_link)\n",
    "    else:\n",
    "        title = url_link.split('/')[-1].split('?')[0].split('.')[0]\n",
    "    \n",
    "    return media_type, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_media_content(user_data):\n",
    "    media_content = [extract_url_title(twt) for twt in user_data]\n",
    "    \n",
    "    media_type, title = zip(*media_content)\n",
    "    n_photo = media_type.count('photo')\n",
    "    n_video = media_type.count('video')\n",
    "    title = [item for item in title if item is not None]\n",
    "    \n",
    "    return n_photo, n_video, title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_tweets(user_data):\n",
    "    \"\"\"Data pada key \"tweets\" terdiri atas independent & dependent tweet.\n",
    "    \n",
    "    Independent tweet = tweet yang dibuat sendiri (inspirasi sendiri)\n",
    "    Dependent tweet = tweet yang mengutip/quote tweet org lain (quoted tweet)\"\"\"\n",
    "    \n",
    "    list_tweets, list_quoted_tweets = [], []\n",
    "    \n",
    "    for twt in user_data['tweets']:\n",
    "        list_tweets.append(twt['full_text'])\n",
    "        try:\n",
    "            list_quoted_tweets.append(twt['quoted_status']['full_text'])\n",
    "        except:\n",
    "            pass\n",
    "    return list_tweets, list_quoted_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_hashtag(list_tweets):   \n",
    "    all_hashtag = []\n",
    "    \n",
    "    wiz = Wizard()\n",
    "    twt_hashtag = wiz.get_hashtag(pd.Series(list_tweets))['Hashtag']\n",
    "    n_twt_use_hashtag = len(twt_hashtag)\n",
    "    \n",
    "    for i in twt_hashtag:\n",
    "        all_hashtag += i\n",
    "    return n_twt_use_hashtag, all_hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_related_feat(list_tweets):\n",
    "    n_twt_use_hashtag, all_hashtag = get_all_hashtag(list_tweets)\n",
    "    \n",
    "    if n_twt_use_hashtag != 0:\n",
    "        ratio = (n_twt_use_hashtag/len(list_tweets))\n",
    "    else:\n",
    "        ratio = 0\n",
    "    return all_hashtag, n_twt_use_hashtag, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc(filename, user_data, username_desc):\n",
    "    username = filename.split('/')[-1][:-5]\n",
    "    if not username.startswith('@'):\n",
    "        desc = username_desc.get(username)[1]\n",
    "    else:\n",
    "        desc = user_data['description']\n",
    "    return username, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_features = []\n",
    "\n",
    "for filename in tqdm(glob.glob(data_path)[:2]):\n",
    "    user_data = read_json(filename)\n",
    "    # Separate tweets\n",
    "    list_tweets, list_quoted_tweets = separate_tweets(user_data)\n",
    "    # Extract hashtag related features\n",
    "    all_hashtag, n_twt_use_hashtag, ratio = hashtag_related_feat(list_tweets)\n",
    "    # Get username description\n",
    "    profile_id = read_json(profile_data_path)\n",
    "    username_desc = {user['screen_name']:(user['name'], user['description']) for user in profile_id}\n",
    "    username, desc = get_desc(filename, user_data, username_desc)\n",
    "    # Get summary of media content\n",
    "    n_photo, n_video, title = summary_media_content(user_data['tweets'])\n",
    "\n",
    "    \n",
    "    # Output\n",
    "    feat = {'username': username, \n",
    "            'name': username_desc.get(username)[0],\n",
    "            'desc': desc,\n",
    "            'tweets': list_tweets,\n",
    "            'n_tweet': len(list_tweets),\n",
    "            'quoted_tweets': list_quoted_tweets,\n",
    "            'hashtag': all_hashtag,\n",
    "            'n_tweet_use_hashtag': n_twt_use_hashtag,\n",
    "            'ratio_tweets_use_hashtag': ratio,\n",
    "            'n_photo': n_photo,\n",
    "            'n_video': n_video,\n",
    "            'content_title': title}\n",
    "    raw_features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'username': 'GantengPendekar',\n",
       " 'name': 'Pendekar Ganteng',\n",
       " 'desc': 'Anak Sulung | penyanyi amatir | pansos',\n",
       " 'tweets': ['PDIP adalah TARGET\\n\\n#NewNormalDinodaiKadrun https://t.co/8oQpKJY0R4',\n",
       "  'Aksi didepan gedung DPR mau menyelamatkan pancasila? Agama minoritas aja ditindas dan dilarang oleh mereka. Wkwkwk https://t.co/cXY2yYvVLA',\n",
       "  'Pemerintah Pastikan Insentif Kartu Prakerja Cair Pekan Ini https://t.co/W3yYbiTmHY\\n\\n#TolakProvokasiDitengahPandemi',\n",
       "  'Soekarno Meninggal Dunia pada Ulang Tahun Jokowi yang ke-9\\n\\nUtas\\n\\nOleh: Pical Gadi\\n#JagaDanPerkuatPancasila https://t.co/cgrNs9UGJK',\n",
       "  'Indonesian President Joko to resume working trips next week as country eases restrictions\\nhttps://t.co/1WrnrIyyfZ\\n\\n#JumatBerkah',\n",
       "  'RUU HIP Haluan Ideologi Pancasila dijegal oleh Kelompok Radikal\\n\\n#IndonesiaDaruratHumor https://t.co/xBYF6M0kNT',\n",
       "  'ESENSI PANCASILA ITU GOTONG ROYONG\\n\\nSebuah thread melawan penyesatan narasi pancasila\\n#TokopediaxBTS https://t.co/RPvnB353ii',\n",
       "  'Di Balik Pesan Jokowi untuk Menggigit \"Koruptor Corona\"\\n\\nUtas\\n\\nOleh: Kholil Rohmah\\n#BINTANGEMONBESTBOY',\n",
       "  'Ketahui kriteria risiko daerah berdasarkan warnanya dan pahami artinya. \\n\\nTetaplah waspada dalam menjaga diri dan selalu ikuti protokol kesehatan dimanapun anda berada demi keselamatan bersama!\\n#KemenagBisu https://t.co/meqQi9vws5',\n",
       "  'Untuk mengukur suatu wabah penyakit penular apakah dapat dikendalikan atau tidak, salah satu indikator yang dilihat ialah tingkat reproduksi atau R dari penyakit atau virus tersebut.\\n\\n#PSBBTransisi4niesGagal https://t.co/haWTxBDK2o',\n",
       "  'Spanduk \"Kami Menolak Rapid Tes\" Mulai Menjamur di Kota Makassar, Ada Apa?\\n\\n(((thread)))\\n\\nOleh: Pattarani SH\\n#PapuaNegeriku https://t.co/2wXFvGtAnK',\n",
       "  'Jokowi Calls on Indonesians to Exercise to Boost Immune System\\n\\nhttps://t.co/ZnV4QhkPfz\\n\\n#TNIPolriSolidUntukNegeri',\n",
       "  'Era New Normal, Akankah Menjadi Akhir Senjakala UMKM?\\n\\n((Thread))\\n\\nOleh: Sutrisno\\n#SeninAmbyar https://t.co/TR77uHUDvV',\n",
       "  'Menunaikan Salat Jumat Dibagi Menjadi 2 Gelombang?\\n\\nUtas\\n\\nOleh: Ahmad Sugeng Riadi\\n#JumatBerkah https://t.co/omynvp2ADa',\n",
       "  'Akhirnya, Pemerintah Indonesia Resmi Batalkan Keberangkatan Jemaah Haji Tahun Ini\\n\\nUtas\\n\\nOleh: Wiwin Zein\\n#Putusin https://t.co/u1fp94nyZl',\n",
       "  'BREAKING NEWS\\nNew Normal dan Peran Penting Masyarakat di Dalamnya\\n\\nUtas\\n\\nOleh: Gatot Purwanto https://t.co/u7Vf8XSY3a'],\n",
       " 'n_tweet': 16,\n",
       " 'quoted_tweets': [],\n",
       " 'hashtag': ['NewNormalDinodaiKadrun',\n",
       "  'TolakProvokasiDitengahPandemi',\n",
       "  'JagaDanPerkuatPancasila',\n",
       "  'JumatBerkah',\n",
       "  'IndonesiaDaruratHumor',\n",
       "  'TokopediaxBTS',\n",
       "  'BINTANGEMONBESTBOY',\n",
       "  'KemenagBisu',\n",
       "  'PSBBTransisi4niesGagal',\n",
       "  'PapuaNegeriku',\n",
       "  'TNIPolriSolidUntukNegeri',\n",
       "  'SeninAmbyar',\n",
       "  'JumatBerkah',\n",
       "  'Putusin'],\n",
       " 'n_tweet_use_hashtag': 14,\n",
       " 'ratio_tweets_use_hashtag': 0.875,\n",
       " 'n_photo': 12,\n",
       " 'n_video': 0,\n",
       " 'content_title': ['pemerintah-pastikan-insentif-kartu-prakerja-cair-pekan-ini',\n",
       "  'indonesia-president-joko-widodo-to-resume-working-trips-next-week-as-country-eases',\n",
       "  'jokowi-calls-on-indonesians-to-exercise-to-boost-immune-system']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
