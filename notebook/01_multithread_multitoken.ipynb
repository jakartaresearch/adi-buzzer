{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading and Multitoken experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import tweepy\n",
    "from socket import gaierror"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multithreading and multitoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compress \n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "storage = []\n",
    "tokens = [True] * 2\n",
    "\n",
    "def get_free_token(tokens):\n",
    "    idx_tokens = list(compress(range(len(tokens)), tokens))\n",
    "    if len(idx_tokens) > 0:\n",
    "        return idx_tokens[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def do_something(seconds, idx_token):\n",
    "    print(f'\\tsleeping {seconds} seconds using token {idx_token}')\n",
    "    time.sleep(seconds)\n",
    "    storage.append(seconds)\n",
    "    print(f'Done Sleeping in {seconds} using token {idx_token}')\n",
    "    tokens[idx_token] = True\n",
    "\n",
    "def submission(executor, num, idx_token):\n",
    "    print(\"\\tidx token\", idx_token, \"is used\")\n",
    "    executor.submit(do_something, num, idx_token)\n",
    "\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    data = [5,1,1,1,1,1]\n",
    "    for num in data:\n",
    "        print(\"tokens status\", tokens)\n",
    "        while True:\n",
    "            idx_token = get_free_token(tokens)\n",
    "            try:\n",
    "                tokens[idx_token] = False\n",
    "                status = submission(executor, num, idx_token)\n",
    "                print(\"\\tafter submission tokens\", tokens)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "print(storage)\n",
    "\n",
    "stop = time.perf_counter()\n",
    "\n",
    "print(f'finished all process in {round(stop-start, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_paths = glob.glob(\"../keys/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apis = []\n",
    "for path in key_paths:\n",
    "    key = pickle.load(open(path, 'rb'))\n",
    "    auth = tweepy.OAuthHandler(key[\"api_key\"], key[\"api_secret_key\"])\n",
    "    auth.set_access_token(key[\"access_token\"], key[\"access_token_secret\"])\n",
    "    api = tweepy.API(auth)\n",
    "    apis.append(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for api in apis:\n",
    "    rate_limit_dict = api.rate_limit_status()\n",
    "    rate_limit_dict = rate_limit_dict[\"resources\"]\n",
    "#     print(\"/users/show/:id\", rate_limit_dict[\"users\"][\"/users/show/:id\"])\n",
    "    print(\"/friends/list\", rate_limit_dict[\"friends\"][\"/friends/list\"])\n",
    "#     print(\"/search/tweets\", rate_limit_dict[\"search\"])\n",
    "#     print(\"/statuses/user_timeline\", rate_limit_dict[\"statuses\"][\"/statuses/user_timeline\"])\n",
    "    print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob('../data/profile/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob('../data/following/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for path in paths:\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        data_list.append((path, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [(path, data) for path, data in data_list if 'status' in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [(path, data) for path, data in data_list if data[\"friends_count\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, data in data_list:\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
