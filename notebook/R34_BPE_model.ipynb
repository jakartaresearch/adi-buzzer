{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BPE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load multiple features dataset\n",
    "X_train_multi = load_data('../data/dataset/X_train_bpe_multi.npy')\n",
    "y_train_multi = load_data('../data/dataset/y_train_bpe_multi.npy')\n",
    "\n",
    "X_test_multi = load_data('../data/dataset/X_test_bpe_multi.npy')\n",
    "y_test_multi = load_data('../data/dataset/y_test_bpe_multi.npy')\n",
    "\n",
    "## Load single feature dataset\n",
    "X_train_single = load_data('../data/dataset/X_train_bpe_single.npy')\n",
    "y_train_single = load_data('../data/dataset/y_train_bpe_single.npy')\n",
    "\n",
    "X_test_single = load_data('../data/dataset/X_test_bpe_single.npy')\n",
    "y_test_single = load_data('../data/dataset/y_test_bpe_single.npy')\n",
    "\n",
    "multi_dataset = [X_train_multi, y_train_multi, X_test_multi, y_test_multi]\n",
    "single_dataset = [X_train_single, y_train_single, X_test_single, y_test_single]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2369, 605)\n",
      "(593, 605)\n",
      "(2369, 300)\n",
      "(593, 300)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_multi.shape)\n",
    "print(X_test_multi.shape)\n",
    "\n",
    "print(X_train_single.shape)\n",
    "print(X_test_single.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling data (Minor class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42, k_neighbors=10, n_jobs=-1)\n",
    "\n",
    "X_train_multiover, y_train_multiover = sm.fit_sample(multi_dataset[0], multi_dataset[1])\n",
    "X_train_singleover, y_train_singleover = sm.fit_sample(single_dataset[0], single_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([1840, 1840]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_multiover, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([1840, 1840]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_singleover, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model (SVC, RFC, XGBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_test, y_pred):\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    pre = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"accuracy: {acc:.2f} | precision: {pre:.2f} | recall: {rec:.2f} | f score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(random_state=42)\n",
    "rfc = RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=6)\n",
    "xgboost = XGBClassifier(random_state=42, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.84 | precision: 0.59 | recall: 0.73 | f score: 0.65\n"
     ]
    }
   ],
   "source": [
    "svc_model.fit(X_train_singleover, y_train_singleover)\n",
    "y_pred = svc_model.predict(X_test_single)\n",
    "scoring(y_test_single, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.86 | precision: 0.68 | recall: 0.57 | f score: 0.62\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train_singleover, y_train_singleover)\n",
    "y_pred = rfc.predict(X_test_single)\n",
    "scoring(y_test_single, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryx/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:37:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy: 0.86 | precision: 0.66 | recall: 0.62 | f score: 0.64\n"
     ]
    }
   ],
   "source": [
    "xgboost.fit(X_train_singleover, y_train_singleover)\n",
    "y_pred = xgboost.predict(X_test_single)\n",
    "scoring(y_test_single, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"XGBoost\" : {\"algo\" : XGBClassifier(random_state=42, verbosity=1, n_jobs=-1),\n",
    "                 \"parameter\" : {'min_child_weight': [1, 5, 10],\n",
    "                                'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "                                'subsample': [0.6, 0.8, 1.0],\n",
    "                                'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "                                'max_depth': [3, 4, 5]}\n",
    "                },\n",
    "    \n",
    "    \"Random Forest\" : {\"algo\" : RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "                       \"parameter\" : {\"n_estimators\" : [100, 200, 300, 400, 500],\n",
    "                                      \"criterion\" : ['gini', 'entropy'],\n",
    "                                      \"max_features\" : ['auto', 'sqrt', 'log2']}\n",
    "                      }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tuning(model, model_param: dict, x_train, y_train, n_iteration, score, split):\n",
    "    search = RandomizedSearchCV(model, model_param, n_iter=n_iteration, scoring=score, cv=split, verbose=1, n_jobs=-1)\n",
    "    search.fit(x_train, y_train)\n",
    "    print(\"Model={} \\nScore={} \".format(model, search.best_score_))\n",
    "    metric = search.best_score_\n",
    "    best_param = search.best_estimator_\n",
    "    return best_param, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryx/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:278: UserWarning: The total space of parameters 30 is smaller than n_iter=50. Running 30 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model=RandomForestClassifier(n_jobs=-1, random_state=42) \n",
      "Score=0.8968708528827921 \n"
     ]
    }
   ],
   "source": [
    "rfc_best_param, metric = fine_tuning(models['Random Forest']['algo'], models['Random Forest']['parameter'], \n",
    "                                     X_train_singleover, y_train_singleover, 50, \"precision\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(rfc_best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Performance\n",
      "accuracy: 0.86 | precision: 0.69 | recall: 0.58 | f score: 0.63\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation Performance\")\n",
    "y_pred = rfc_best_param.predict(X_test_single)\n",
    "scoring(y_test_single, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "param_comb = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  30 | elapsed: 16.8min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 17.8min finished\n",
      "/home/ryx/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:01:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7f9970b0ef90>,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing...\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=42, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'max_depth': [3, 4, 5],\n",
       "                                        'min_child_weight': [1, 5, 10],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=42, scoring='precision', verbose=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(models['XGBoost']['algo'], param_distributions=models['XGBoost']['parameter'], \n",
    "                                   n_iter=param_comb, scoring='precision', n_jobs=-1, \n",
    "                                   cv=skf.split(X_train_singleover, y_train_singleover), \n",
    "                                   verbose=3, random_state=42)\n",
    "\n",
    "random_search.fit(X_train_singleover, y_train_singleover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Performance\n",
      "accuracy: 0.85 | precision: 0.63 | recall: 0.60 | f score: 0.62\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation Performance\")\n",
    "y_pred = random_search.predict(X_test_single)\n",
    "scoring(y_test_single, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
