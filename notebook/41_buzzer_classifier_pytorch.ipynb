{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import string\n",
    "import itertools\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input path\n",
    "SUPPORT_PATH = \"../data/supports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_199 = read_pickle(os.path.join(SUPPORT_PATH, \"parsed_199.pkl\"))\n",
    "d_6725 = read_pickle(os.path.join(SUPPORT_PATH, \"parsed_7003.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tweets = pd.concat([d_199, d_6725], axis = 0, sort=False)\n",
    "d_tweets.drop_duplicates(subset=\"id_tweet\", inplace=True)\n",
    "d_tweets.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_label = pd.read_csv(\"../data/account_labeled/label_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4SinCong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4rdipratama</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABackBone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARUL77039666</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATAP03167829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    screen_name  label\n",
       "0      4SinCong    NaN\n",
       "1   4rdipratama    NaN\n",
       "2     ABackBone    NaN\n",
       "3  ARUL77039666    NaN\n",
       "4  ATAP03167829    NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41756, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>id_tweet</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>created_at</th>\n",
       "      <th>quote_is_quote_status</th>\n",
       "      <th>quote_screen_name</th>\n",
       "      <th>quote_id_tweet</th>\n",
       "      <th>quote_full_text</th>\n",
       "      <th>quote_hashtags</th>\n",
       "      <th>quote_user_mentions</th>\n",
       "      <th>quote_created_at</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212Ujee2</td>\n",
       "      <td>1272955449160040449</td>\n",
       "      <td>#HapusRUUHIPDariMukaBumi \\n#HapusRUUHIPDariMuk...</td>\n",
       "      <td>[{'text': 'HapusRUUHIPDariMukaBumi', 'indices'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tue Jun 16 18:13:24 +0000 2020</td>\n",
       "      <td>True</td>\n",
       "      <td>Par3w4_Minang</td>\n",
       "      <td>1272901801516335112</td>\n",
       "      <td>Moncong putih ingin cuci tangan \\n\\nKata si Po...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tue Jun 16 14:40:13 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212Ujee2</td>\n",
       "      <td>1272573148974571526</td>\n",
       "      <td>Sampah n benalu\\nPerusak demokrasi wajib kita ...</td>\n",
       "      <td>[{'text': 'BuzzeRpPublicEnemy', 'indices': [59...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Mon Jun 15 16:54:16 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>212Ujee2</td>\n",
       "      <td>1272242834725208064</td>\n",
       "      <td>Saatnya kita bersatu\\nWahai umat Islam\\n\\n#Sto...</td>\n",
       "      <td>[{'text': 'Stop_RUUHIP', 'indices': [39, 51]},...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Sun Jun 14 19:01:43 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212Ujee2</td>\n",
       "      <td>1267860265694978049</td>\n",
       "      <td>Umat Islam\\nHrs diam \\nTerus sampai kapan?\\nKe...</td>\n",
       "      <td>[{'text': 'BalikinDanaHaji', 'indices': [104, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tue Jun 02 16:46:57 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212Ujee2</td>\n",
       "      <td>1266354000716107780</td>\n",
       "      <td>Hai Pemimpin !!!\\nApakah udh ga ada lagi \\nPro...</td>\n",
       "      <td>[{'text': 'DirutBokep', 'indices': [204, 215]}...</td>\n",
       "      <td>[{'screen_name': '__p3jalan____', 'name': 'p3j...</td>\n",
       "      <td>Fri May 29 13:01:36 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  screen_name             id_tweet  \\\n",
       "0    212Ujee2  1272955449160040449   \n",
       "1    212Ujee2  1272573148974571526   \n",
       "2    212Ujee2  1272242834725208064   \n",
       "3    212Ujee2  1267860265694978049   \n",
       "4    212Ujee2  1266354000716107780   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  #HapusRUUHIPDariMukaBumi \\n#HapusRUUHIPDariMuk...   \n",
       "1  Sampah n benalu\\nPerusak demokrasi wajib kita ...   \n",
       "2  Saatnya kita bersatu\\nWahai umat Islam\\n\\n#Sto...   \n",
       "3  Umat Islam\\nHrs diam \\nTerus sampai kapan?\\nKe...   \n",
       "4  Hai Pemimpin !!!\\nApakah udh ga ada lagi \\nPro...   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [{'text': 'HapusRUUHIPDariMukaBumi', 'indices'...   \n",
       "1  [{'text': 'BuzzeRpPublicEnemy', 'indices': [59...   \n",
       "2  [{'text': 'Stop_RUUHIP', 'indices': [39, 51]},...   \n",
       "3  [{'text': 'BalikinDanaHaji', 'indices': [104, ...   \n",
       "4  [{'text': 'DirutBokep', 'indices': [204, 215]}...   \n",
       "\n",
       "                                       user_mentions  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [{'screen_name': '__p3jalan____', 'name': 'p3j...   \n",
       "\n",
       "                       created_at quote_is_quote_status quote_screen_name  \\\n",
       "0  Tue Jun 16 18:13:24 +0000 2020                  True     Par3w4_Minang   \n",
       "1  Mon Jun 15 16:54:16 +0000 2020                   NaN               NaN   \n",
       "2  Sun Jun 14 19:01:43 +0000 2020                   NaN               NaN   \n",
       "3  Tue Jun 02 16:46:57 +0000 2020                   NaN               NaN   \n",
       "4  Fri May 29 13:01:36 +0000 2020                   NaN               NaN   \n",
       "\n",
       "        quote_id_tweet                                    quote_full_text  \\\n",
       "0  1272901801516335112  Moncong putih ingin cuci tangan \\n\\nKata si Po...   \n",
       "1                  NaN                                                NaN   \n",
       "2                  NaN                                                NaN   \n",
       "3                  NaN                                                NaN   \n",
       "4                  NaN                                                NaN   \n",
       "\n",
       "  quote_hashtags quote_user_mentions                quote_created_at  \\\n",
       "0             []                  []  Tue Jun 16 14:40:13 +0000 2020   \n",
       "1            NaN                 NaN                             NaN   \n",
       "2            NaN                 NaN                             NaN   \n",
       "3            NaN                 NaN                             NaN   \n",
       "4            NaN                 NaN                             NaN   \n",
       "\n",
       "  in_reply_to_status_id_str in_reply_to_user_id_str in_reply_to_screen_name  \n",
       "0                       NaN                     NaN                     NaN  \n",
       "1                       NaN                     NaN                     NaN  \n",
       "2                       NaN                     NaN                     NaN  \n",
       "3                       NaN                     NaN                     NaN  \n",
       "4                       NaN                     NaN                     NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1983967, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_label = d_label[~d_label.label.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34900</th>\n",
       "      <td>007koteka</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34901</th>\n",
       "      <td>02Trus</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34902</th>\n",
       "      <td>02fc71ba00c2451</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34903</th>\n",
       "      <td>0b4tk3lu4r94</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34904</th>\n",
       "      <td>0m_Brewoks2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           screen_name  label\n",
       "34900        007koteka    1.0\n",
       "34901           02Trus    1.0\n",
       "34902  02fc71ba00c2451    1.0\n",
       "34903     0b4tk3lu4r94    0.0\n",
       "34904      0m_Brewoks2    0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4978\n",
       "1.0    1878\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_label.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6856,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2797 accounts are labeled, the rest are excluded before parsing\n",
    "d_tweets[d_tweets.screen_name.isin(d_label.screen_name)].screen_name.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dataset = d_tweets.groupby('screen_name')['full_text'].apply(list)\n",
    "d_dataset = d_dataset.reset_index()\n",
    "\n",
    "# join dataset and label\n",
    "d_dataset = d_dataset.join(d_label.set_index('screen_name'), on='screen_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile_key(screen_name, key):\n",
    "    profile_path = os.path.join(f\"../data/profile/{screen_name}.json\")\n",
    "    if os.path.exists(profile_path):\n",
    "        with open(profile_path) as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data, dict):\n",
    "                return data.get(key, None)\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 6856/6856 [00:00<00:00, 13467.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# get verified\n",
    "d_dataset[\"is_verified\"] = d_dataset.screen_name.progress_apply(get_profile_key, args=('verified', ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2981\n",
       "True       95\n",
       "Name: is_verified, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset.is_verified.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 6856/6856 [00:00<00:00, 13748.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# get description profile\n",
    "d_dataset[\"profile_description\"] = d_dataset.screen_name.progress_apply(get_profile_key, args=('description', ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_akun_resmi(description):\n",
    "    if description:\n",
    "        if re.search(\"akun .* resmi\", description.lower()):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dataset[\"is_akun_resmi\"] = d_dataset.profile_description.apply(check_akun_resmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dataset.loc[:, 'num_tweets'] = d_dataset.full_text.apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4978\n",
       "1.0    1878\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dataset2 = d_dataset[d_dataset.num_tweets >= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6856, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6720, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4876\n",
       "1.0    1844\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset2.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-ae763a85b7fa>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_dataset2['text_used'] = d_dataset2.full_text.apply(lambda x: \" \".join(x[:n_tweets]))\n"
     ]
    }
   ],
   "source": [
    "# using n samples\n",
    "n_tweets = 5\n",
    "d_dataset2['text_used'] = d_dataset2.full_text.apply(lambda x: \" \".join(x[:n_tweets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6720, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dataset2 = d_dataset2[d_dataset2.label.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dataset2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6720, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleansing(title):\n",
    "    punctuation = '!\"#$%&\\'()*+,-./:;=?@[\\\\]^_`{|}~'\n",
    "    table = str.maketrans(punctuation, ' '*len(punctuation)) #map punctuation to space\n",
    "    \n",
    "    # parse hashtag\n",
    "    title = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", title)\n",
    "    # lowercase\n",
    "    title = title.lower()\n",
    "    # convert hyperlinks to link\n",
    "#     title = re.sub('http(s):/\\/\\\\S+', '<LINK> ', title)\n",
    "    title = re.sub('http(s):/\\/\\\\S+', ' ', title)\n",
    "    # convert @username to username\n",
    "#     title = re.sub('@\\w+', '<USERNAME>', title)\n",
    "    title = re.sub('@\\w+', ' ', title)\n",
    "    # remove punctuation\n",
    "    title = title.translate(table)\n",
    "    # only take string started with alphanum\n",
    "    title = re.sub(\"[^(\\w|\\<\\>)]\", ' ', title)\n",
    "    # remove double whitespaces\n",
    "    title = re.sub('\\s+', ' ', title)\n",
    "    # remove double whitespaces\n",
    "    title = title.strip()\n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(title)\n",
    "    # filter tokens more than 2 characters\n",
    "    tokens = list(filter(lambda x: len(x) > 2, tokens))\n",
    "    # filter tokens not numeric only\n",
    "    tokens = list(filter(lambda x: not x.isnumeric(), tokens))\n",
    "    # revert to string\n",
    "    title = \" \".join(tokens)\n",
    "    \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dataset2[\"preprocessed_text\"] = d_dataset2.text_used.apply(text_cleansing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>full_text</th>\n",
       "      <th>label</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>profile_description</th>\n",
       "      <th>is_akun_resmi</th>\n",
       "      <th>num_tweets</th>\n",
       "      <th>text_used</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007koteka</td>\n",
       "      <td>[#HariJadiTwitterSaya \\n28 Juni 2017 https://t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>- Jadilah Penyejuk Hati yang Gersang l    \\n  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>#HariJadiTwitterSaya \\n28 Juni 2017 https://t....</td>\n",
       "      <td>hari jadi twitter saya juni penjilat yang berk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02Trus</td>\n",
       "      <td>[RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeb...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeba...</td>\n",
       "      <td>moslem1 asyeeekkk pdip kena jebakan batman fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fc71ba00c2451</td>\n",
       "      <td>[Salah ketik, salah hitung, salah input, salah...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>benci dengan kemunafikan</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Salah ketik, salah hitung, salah input, salah ...</td>\n",
       "      <td>salah ketik salah hitung salah input salah sia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0b4tk3lu4r94</td>\n",
       "      <td>[Sebentar....bentar gue hrs inget2 nih berukny...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Bergerak dan berdoa teros ajah</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Sebentar....bentar gue hrs inget2 nih beruknya...</td>\n",
       "      <td>sebentar bentar gue hrs inget2 nih beruknya sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0m_Brewoks2</td>\n",
       "      <td>[Bismillah. Bagi Yg minat kaos,topi #ManusiaMe...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Bismillah. Bagi Yg minat kaos,topi #ManusiaMer...</td>\n",
       "      <td>bismillah bagi minat kaos topi manusia merdeka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6715</th>\n",
       "      <td>zulfikarzat31</td>\n",
       "      <td>[Baru saja mengirim foto https://t.co/xh415Eyj...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>💗Di beranda, kita pernah lupa bahwa cinta bisa...</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Baru saja mengirim foto https://t.co/xh415Eyj2...</td>\n",
       "      <td>baru saja mengirim foto ijin share qah sisa ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6716</th>\n",
       "      <td>zulhermansyah97</td>\n",
       "      <td>[👁 Siapa yang melawat profil anda? 👁\\n@ArifinN...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Lelah 🔜 Lillah</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>👁 Siapa yang melawat profil anda? 👁\\n@ArifinNa...</td>\n",
       "      <td>siapa yang melawat profil anda naftalia min so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6717</th>\n",
       "      <td>zulkifli_abdul9</td>\n",
       "      <td>[Ini kenapa aku gak segampang itu ngambil kese...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Football manager addict, ava nya alim orang ny...</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Ini kenapa aku gak segampang itu ngambil kesem...</td>\n",
       "      <td>ini kenapa aku gak segampang itu ngambil kesem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718</th>\n",
       "      <td>zulman1</td>\n",
       "      <td>[Hmm bisa di coba ini wkwkw https://t.co/qCGES...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Juru tulis kapal bajak laut yang sedang berlay...</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Hmm bisa di coba ini wkwkw https://t.co/qCGESp...</td>\n",
       "      <td>hmm bisa coba ini wkwkw cgesp wyw garuda dadak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6719</th>\n",
       "      <td>zulvitano</td>\n",
       "      <td>[aku orang yang suka nahan kentut dari magrib ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>apa yang kamu beri apa yang kamu dapatkan dike...</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>aku orang yang suka nahan kentut dari magrib s...</td>\n",
       "      <td>aku orang yang suka nahan kentut dari magrib s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6720 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_name                                          full_text  \\\n",
       "0           007koteka  [#HariJadiTwitterSaya \\n28 Juni 2017 https://t...   \n",
       "1              02Trus  [RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeb...   \n",
       "2     02fc71ba00c2451  [Salah ketik, salah hitung, salah input, salah...   \n",
       "3        0b4tk3lu4r94  [Sebentar....bentar gue hrs inget2 nih berukny...   \n",
       "4         0m_Brewoks2  [Bismillah. Bagi Yg minat kaos,topi #ManusiaMe...   \n",
       "...               ...                                                ...   \n",
       "6715    zulfikarzat31  [Baru saja mengirim foto https://t.co/xh415Eyj...   \n",
       "6716  zulhermansyah97  [👁 Siapa yang melawat profil anda? 👁\\n@ArifinN...   \n",
       "6717  zulkifli_abdul9  [Ini kenapa aku gak segampang itu ngambil kese...   \n",
       "6718          zulman1  [Hmm bisa di coba ini wkwkw https://t.co/qCGES...   \n",
       "6719        zulvitano  [aku orang yang suka nahan kentut dari magrib ...   \n",
       "\n",
       "      label is_verified                                profile_description  \\\n",
       "0       1.0       False  - Jadilah Penyejuk Hati yang Gersang l    \\n  ...   \n",
       "1       1.0        None                                               None   \n",
       "2       1.0       False                           benci dengan kemunafikan   \n",
       "3       0.0       False                     Bergerak dan berdoa teros ajah   \n",
       "4       0.0        None                                               None   \n",
       "...     ...         ...                                                ...   \n",
       "6715    0.0       False  💗Di beranda, kita pernah lupa bahwa cinta bisa...   \n",
       "6716    0.0       False                                     Lelah 🔜 Lillah   \n",
       "6717    0.0       False  Football manager addict, ava nya alim orang ny...   \n",
       "6718    0.0       False  Juru tulis kapal bajak laut yang sedang berlay...   \n",
       "6719    0.0       False  apa yang kamu beri apa yang kamu dapatkan dike...   \n",
       "\n",
       "      is_akun_resmi  num_tweets  \\\n",
       "0             False         300   \n",
       "1             False         300   \n",
       "2             False         300   \n",
       "3             False         300   \n",
       "4             False         300   \n",
       "...             ...         ...   \n",
       "6715          False         300   \n",
       "6716          False         300   \n",
       "6717          False         300   \n",
       "6718          False         300   \n",
       "6719          False         300   \n",
       "\n",
       "                                              text_used  \\\n",
       "0     #HariJadiTwitterSaya \\n28 Juni 2017 https://t....   \n",
       "1     RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeba...   \n",
       "2     Salah ketik, salah hitung, salah input, salah ...   \n",
       "3     Sebentar....bentar gue hrs inget2 nih beruknya...   \n",
       "4     Bismillah. Bagi Yg minat kaos,topi #ManusiaMer...   \n",
       "...                                                 ...   \n",
       "6715  Baru saja mengirim foto https://t.co/xh415Eyj2...   \n",
       "6716  👁 Siapa yang melawat profil anda? 👁\\n@ArifinNa...   \n",
       "6717  Ini kenapa aku gak segampang itu ngambil kesem...   \n",
       "6718  Hmm bisa di coba ini wkwkw https://t.co/qCGESp...   \n",
       "6719  aku orang yang suka nahan kentut dari magrib s...   \n",
       "\n",
       "                                      preprocessed_text  \n",
       "0     hari jadi twitter saya juni penjilat yang berk...  \n",
       "1     moslem1 asyeeekkk pdip kena jebakan batman fra...  \n",
       "2     salah ketik salah hitung salah input salah sia...  \n",
       "3     sebentar bentar gue hrs inget2 nih beruknya sa...  \n",
       "4     bismillah bagi minat kaos topi manusia merdeka...  \n",
       "...                                                 ...  \n",
       "6715  baru saja mengirim foto ijin share qah sisa ha...  \n",
       "6716  siapa yang melawat profil anda naftalia min so...  \n",
       "6717  ini kenapa aku gak segampang itu ngambil kesem...  \n",
       "6718  hmm bisa coba ini wkwkw cgesp wyw garuda dadak...  \n",
       "6719  aku orang yang suka nahan kentut dari magrib s...  \n",
       "\n",
       "[6720 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dataset2.label = d_dataset2.label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4876\n",
       "1    1844\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset2.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='label'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_dataset2.label.value_counts().plot(kind='pie', autopct='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Count Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>full_text</th>\n",
       "      <th>label</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>profile_description</th>\n",
       "      <th>is_akun_resmi</th>\n",
       "      <th>num_tweets</th>\n",
       "      <th>text_used</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007koteka</td>\n",
       "      <td>[#HariJadiTwitterSaya \\n28 Juni 2017 https://t...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>- Jadilah Penyejuk Hati yang Gersang l    \\n  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>#HariJadiTwitterSaya \\n28 Juni 2017 https://t....</td>\n",
       "      <td>hari jadi twitter saya juni penjilat yang berk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02Trus</td>\n",
       "      <td>[RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeb...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeba...</td>\n",
       "      <td>moslem1 asyeeekkk pdip kena jebakan batman fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fc71ba00c2451</td>\n",
       "      <td>[Salah ketik, salah hitung, salah input, salah...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>benci dengan kemunafikan</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Salah ketik, salah hitung, salah input, salah ...</td>\n",
       "      <td>salah ketik salah hitung salah input salah sia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0b4tk3lu4r94</td>\n",
       "      <td>[Sebentar....bentar gue hrs inget2 nih berukny...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Bergerak dan berdoa teros ajah</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Sebentar....bentar gue hrs inget2 nih beruknya...</td>\n",
       "      <td>sebentar bentar gue hrs inget2 nih beruknya sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0m_Brewoks2</td>\n",
       "      <td>[Bismillah. Bagi Yg minat kaos,topi #ManusiaMe...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Bismillah. Bagi Yg minat kaos,topi #ManusiaMer...</td>\n",
       "      <td>bismillah bagi minat kaos topi manusia merdeka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                          full_text  label  \\\n",
       "0        007koteka  [#HariJadiTwitterSaya \\n28 Juni 2017 https://t...      1   \n",
       "1           02Trus  [RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeb...      1   \n",
       "2  02fc71ba00c2451  [Salah ketik, salah hitung, salah input, salah...      1   \n",
       "3     0b4tk3lu4r94  [Sebentar....bentar gue hrs inget2 nih berukny...      0   \n",
       "4      0m_Brewoks2  [Bismillah. Bagi Yg minat kaos,topi #ManusiaMe...      0   \n",
       "\n",
       "  is_verified                                profile_description  \\\n",
       "0       False  - Jadilah Penyejuk Hati yang Gersang l    \\n  ...   \n",
       "1        None                                               None   \n",
       "2       False                           benci dengan kemunafikan   \n",
       "3       False                     Bergerak dan berdoa teros ajah   \n",
       "4        None                                               None   \n",
       "\n",
       "   is_akun_resmi  num_tweets  \\\n",
       "0          False         300   \n",
       "1          False         300   \n",
       "2          False         300   \n",
       "3          False         300   \n",
       "4          False         300   \n",
       "\n",
       "                                           text_used  \\\n",
       "0  #HariJadiTwitterSaya \\n28 Juni 2017 https://t....   \n",
       "1  RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeba...   \n",
       "2  Salah ketik, salah hitung, salah input, salah ...   \n",
       "3  Sebentar....bentar gue hrs inget2 nih beruknya...   \n",
       "4  Bismillah. Bagi Yg minat kaos,topi #ManusiaMer...   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  hari jadi twitter saya juni penjilat yang berk...  \n",
       "1  moslem1 asyeeekkk pdip kena jebakan batman fra...  \n",
       "2  salah ketik salah hitung salah input salah sia...  \n",
       "3  sebentar bentar gue hrs inget2 nih beruknya sa...  \n",
       "4  bismillah bagi minat kaos topi manusia merdeka...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6720, 9)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dataset2['preprocessed_text_token'] = d_dataset2.preprocessed_text.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>full_text</th>\n",
       "      <th>label</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>profile_description</th>\n",
       "      <th>is_akun_resmi</th>\n",
       "      <th>num_tweets</th>\n",
       "      <th>text_used</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>preprocessed_text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007koteka</td>\n",
       "      <td>[#HariJadiTwitterSaya \\n28 Juni 2017 https://t...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>- Jadilah Penyejuk Hati yang Gersang l    \\n  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>#HariJadiTwitterSaya \\n28 Juni 2017 https://t....</td>\n",
       "      <td>hari jadi twitter saya juni penjilat yang berk...</td>\n",
       "      <td>[hari, jadi, twitter, saya, juni, penjilat, ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02Trus</td>\n",
       "      <td>[RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeb...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeba...</td>\n",
       "      <td>moslem1 asyeeekkk pdip kena jebakan batman fra...</td>\n",
       "      <td>[moslem1, asyeeekkk, pdip, kena, jebakan, batm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fc71ba00c2451</td>\n",
       "      <td>[Salah ketik, salah hitung, salah input, salah...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>benci dengan kemunafikan</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Salah ketik, salah hitung, salah input, salah ...</td>\n",
       "      <td>salah ketik salah hitung salah input salah sia...</td>\n",
       "      <td>[salah, ketik, salah, hitung, salah, input, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0b4tk3lu4r94</td>\n",
       "      <td>[Sebentar....bentar gue hrs inget2 nih berukny...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Bergerak dan berdoa teros ajah</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Sebentar....bentar gue hrs inget2 nih beruknya...</td>\n",
       "      <td>sebentar bentar gue hrs inget2 nih beruknya sa...</td>\n",
       "      <td>[sebentar, bentar, gue, hrs, inget2, nih, beru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0m_Brewoks2</td>\n",
       "      <td>[Bismillah. Bagi Yg minat kaos,topi #ManusiaMe...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>300</td>\n",
       "      <td>Bismillah. Bagi Yg minat kaos,topi #ManusiaMer...</td>\n",
       "      <td>bismillah bagi minat kaos topi manusia merdeka...</td>\n",
       "      <td>[bismillah, bagi, minat, kaos, topi, manusia, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                          full_text  label  \\\n",
       "0        007koteka  [#HariJadiTwitterSaya \\n28 Juni 2017 https://t...      1   \n",
       "1           02Trus  [RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeb...      1   \n",
       "2  02fc71ba00c2451  [Salah ketik, salah hitung, salah input, salah...      1   \n",
       "3     0b4tk3lu4r94  [Sebentar....bentar gue hrs inget2 nih berukny...      0   \n",
       "4      0m_Brewoks2  [Bismillah. Bagi Yg minat kaos,topi #ManusiaMe...      0   \n",
       "\n",
       "  is_verified                                profile_description  \\\n",
       "0       False  - Jadilah Penyejuk Hati yang Gersang l    \\n  ...   \n",
       "1        None                                               None   \n",
       "2       False                           benci dengan kemunafikan   \n",
       "3       False                     Bergerak dan berdoa teros ajah   \n",
       "4        None                                               None   \n",
       "\n",
       "   is_akun_resmi  num_tweets  \\\n",
       "0          False         300   \n",
       "1          False         300   \n",
       "2          False         300   \n",
       "3          False         300   \n",
       "4          False         300   \n",
       "\n",
       "                                           text_used  \\\n",
       "0  #HariJadiTwitterSaya \\n28 Juni 2017 https://t....   \n",
       "1  RT @SaveMoslem1: *Asyeeekkk.... PDIP kena jeba...   \n",
       "2  Salah ketik, salah hitung, salah input, salah ...   \n",
       "3  Sebentar....bentar gue hrs inget2 nih beruknya...   \n",
       "4  Bismillah. Bagi Yg minat kaos,topi #ManusiaMer...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  hari jadi twitter saya juni penjilat yang berk...   \n",
       "1  moslem1 asyeeekkk pdip kena jebakan batman fra...   \n",
       "2  salah ketik salah hitung salah input salah sia...   \n",
       "3  sebentar bentar gue hrs inget2 nih beruknya sa...   \n",
       "4  bismillah bagi minat kaos topi manusia merdeka...   \n",
       "\n",
       "                             preprocessed_text_token  \n",
       "0  [hari, jadi, twitter, saya, juni, penjilat, ya...  \n",
       "1  [moslem1, asyeeekkk, pdip, kena, jebakan, batm...  \n",
       "2  [salah, ketik, salah, hitung, salah, input, sa...  \n",
       "3  [sebentar, bentar, gue, hrs, inget2, nih, beru...  \n",
       "4  [bismillah, bagi, minat, kaos, topi, manusia, ...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = itertools.chain.from_iterable(d_dataset2.preprocessed_text_token.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = collections.Counter(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_word_freq = pd.DataFrame(data=word_freq.items(), columns=[\"word\", \"freq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_word_freq = d_word_freq.sort_values(\"freq\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_word_freq = d_word_freq[d_word_freq.freq > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_selected = d_word_freq.word.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['PAD', 'UNK'] + word_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train, d_test = train_test_split(d_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andreaschandra\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\andreaschandra\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "d_train.loc[:, \"token_length\"] = d_train.preprocessed_text_token.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test.loc[:, \"token_length\"] = d_test.preprocessed_text_token.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = d_train.sort_values(\"token_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = d_test.sort_values(\"token_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train.reset_index(drop=True, inplace=True)\n",
    "d_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataset(Dataset):\n",
    "    def __init__(self, d_train, d_test):\n",
    "        self.dataset = {\n",
    "            'train': (d_train, len(d_train)),\n",
    "            'test': (d_test, len(d_test))\n",
    "        }\n",
    "        \n",
    "        self.set_split(split=\"train\")\n",
    "        \n",
    "    def set_split(self, split=\"train\"):\n",
    "        self.data, self.length = self.dataset[split]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        tokens = self.data.loc[index, 'preprocessed_text_token']\n",
    "        label = self.data.loc[index, 'label']\n",
    "        \n",
    "        idx_tokens = []\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                idx_tokens.append(vocab.index(token))\n",
    "            except:\n",
    "                idx_tokens.append(1)\n",
    "                \n",
    "        tokens = torch.tensor(idx_tokens, dtype=torch.long)\n",
    "        \n",
    "        return (tokens, label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Architecture(nn.Module):\n",
    "    def __init__(self, num_vocab, emb_size, hidden_size, num_layer, dropout, is_bidirectional):\n",
    "        super(Architecture, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Embedding(len(vocab), emb_size),\n",
    "            nn.LSTM(emb_size, \n",
    "                    hidden_size, \n",
    "                    num_layers=num_layer, \n",
    "                    bias=False, \n",
    "                    batch_first=True, \n",
    "                    dropout=dropout, \n",
    "                    bidirectional=is_bidirectional)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "         \n",
    "    def forward(self, input_):\n",
    "        out, (h, c) = self.model(input_)\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TwitterDataset(d_train, d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vocab = len(vocab)\n",
    "emb_size = 512\n",
    "hidden_size = 256\n",
    "num_layer = 1\n",
    "dropout = 0\n",
    "is_bidirectional=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Architecture(num_vocab, emb_size, hidden_size, num_layer, dropout, is_bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 12,776,449\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total trainable parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(data):\n",
    "    x, y = zip(*data)\n",
    "    \n",
    "    x = pad_sequence(x, batch_first=True)\n",
    "    y = torch.Tensor(y)\n",
    "    \n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y_true):\n",
    "    y_pred = (y_pred > 0.5).long()\n",
    "    n_correct = torch.eq(y_pred, y_true).sum().item()\n",
    "    \n",
    "    accuracy = (n_correct / len(y_true)) * 100\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | time: 31.9s\n",
      "\t train loss: 0.63 | accuracy: 68.09\n",
      "\t val loss: 0.58 | accuracy: 74.93\n",
      "epoch: 2 | time: 29.8s\n",
      "\t train loss: 0.63 | accuracy: 72.46\n",
      "\t val loss: 0.57 | accuracy: 74.93\n",
      "epoch: 3 | time: 29.9s\n",
      "\t train loss: 0.60 | accuracy: 72.58\n",
      "\t val loss: 0.58 | accuracy: 74.93\n",
      "epoch: 4 | time: 30.1s\n",
      "\t train loss: 0.60 | accuracy: 72.66\n",
      "\t val loss: 0.56 | accuracy: 74.93\n",
      "epoch: 5 | time: 30.6s\n",
      "\t train loss: 0.58 | accuracy: 72.72\n",
      "\t val loss: 0.57 | accuracy: 74.93\n",
      "epoch: 6 | time: 30.5s\n",
      "\t train loss: 0.58 | accuracy: 72.89\n",
      "\t val loss: 0.56 | accuracy: 75.15\n",
      "epoch: 7 | time: 29.8s\n",
      "\t train loss: 0.53 | accuracy: 74.24\n",
      "\t val loss: 0.51 | accuracy: 74.70\n",
      "epoch: 8 | time: 30.4s\n",
      "\t train loss: 0.61 | accuracy: 73.10\n",
      "\t val loss: 0.55 | accuracy: 77.08\n",
      "epoch: 9 | time: 30.0s\n",
      "\t train loss: 0.53 | accuracy: 79.90\n",
      "\t val loss: 0.53 | accuracy: 77.73\n",
      "epoch: 10 | time: 29.9s\n",
      "\t train loss: 0.44 | accuracy: 83.58\n",
      "\t val loss: 0.47 | accuracy: 79.60\n",
      "epoch: 11 | time: 29.6s\n",
      "\t train loss: 0.35 | accuracy: 86.39\n",
      "\t val loss: 0.48 | accuracy: 78.76\n",
      "epoch: 12 | time: 30.1s\n",
      "\t train loss: 0.28 | accuracy: 90.02\n",
      "\t val loss: 0.50 | accuracy: 78.31\n",
      "epoch: 13 | time: 30.1s\n",
      "\t train loss: 0.21 | accuracy: 92.81\n",
      "\t val loss: 0.55 | accuracy: 77.87\n",
      "epoch: 14 | time: 30.6s\n",
      "\t train loss: 0.15 | accuracy: 95.36\n",
      "\t val loss: 0.65 | accuracy: 78.67\n",
      "epoch: 15 | time: 29.8s\n",
      "\t train loss: 0.11 | accuracy: 96.72\n",
      "\t val loss: 0.67 | accuracy: 78.24\n",
      "epoch: 16 | time: 30.1s\n",
      "\t train loss: 0.09 | accuracy: 97.30\n",
      "\t val loss: 0.80 | accuracy: 74.67\n",
      "epoch: 17 | time: 29.4s\n",
      "\t train loss: 0.10 | accuracy: 96.94\n",
      "\t val loss: 0.84 | accuracy: 73.69\n",
      "epoch: 18 | time: 29.6s\n",
      "\t train loss: 0.09 | accuracy: 96.79\n",
      "\t val loss: 0.84 | accuracy: 78.48\n",
      "epoch: 19 | time: 29.3s\n",
      "\t train loss: 0.07 | accuracy: 97.57\n",
      "\t val loss: 0.86 | accuracy: 75.87\n",
      "epoch: 20 | time: 30.3s\n",
      "\t train loss: 0.04 | accuracy: 98.66\n",
      "\t val loss: 0.93 | accuracy: 76.07\n",
      "epoch: 21 | time: 30.7s\n",
      "\t train loss: 0.03 | accuracy: 99.04\n",
      "\t val loss: 1.08 | accuracy: 76.37\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_loss_v = 0\n",
    "    running_acc = 0\n",
    "    running_acc_v = 0\n",
    "    \n",
    "    dataset.set_split(split=\"train\")\n",
    "    data_gen = DataLoader(dataset, batch_size=batch_size, collate_fn=padding)\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(data_gen, 1):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(x)\n",
    "        out = out.squeeze()\n",
    "        \n",
    "        loss = criterion(out , y)\n",
    "        loss.backward()\n",
    "        running_loss += (loss.item() - running_loss) / batch_index \n",
    "        \n",
    "        accuracy = calculate_accuracy(out, y)\n",
    "        running_acc += (accuracy - running_acc) / batch_index\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    dataset.set_split(split=\"test\")\n",
    "    data_gen = DataLoader(dataset, batch_size=batch_size, collate_fn=padding)\n",
    "    model.eval()\n",
    "    for batch_index, (x, y) in enumerate(data_gen, 1):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model(x)\n",
    "            out = out.squeeze()\n",
    "            \n",
    "        loss = criterion(out, y)\n",
    "        running_loss_v += (loss.item() - running_loss_v) / batch_index\n",
    "        \n",
    "        accuracy = calculate_accuracy(out, y)\n",
    "        running_acc_v += (accuracy - running_acc_v) / batch_index\n",
    "    \n",
    "    duration = time.time() - start\n",
    "    print(f\"epoch: {epoch} | time: {duration:.1f}s\")\n",
    "    print(f\"\\t train loss: {running_loss:.2f} | accuracy: {running_acc:.2f}\")\n",
    "    print(f\"\\t val loss: {running_loss_v:.2f} | accuracy: { running_acc_v:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
